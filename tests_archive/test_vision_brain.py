import sys
import os
import pyautogui
import json

# Add current directory to path
sys.path.append(os.getcwd())

from vision_agent import VisionAgent
import config

def run_scenario():
    print("ğŸš€ [SCENARIO: MISSION NEURAL VISION]")
    print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    
    # 1. Initialize
    print("ğŸ§  Initializing Specialized Vision Brain...")
    brain = VisionAgent(config.GROQ_API_KEY)
    
    # 2. Capture
    print("ğŸ“¸ Capturing Screen State...")
    temp_path = "test_scenario_screen.jpg"
    screenshot = pyautogui.screenshot()
    screenshot.save(temp_path)
    
    # 3. Analyze
    # Let's try to find something universal like the "Start" button or any visible icon/text.
    goal = "Find the Windows Start button or any application icon on the taskbar."
    print(f"ğŸ¯ Goal: {goal}")
    print("âš™ï¸ Analyzing... (VLM Consultation)")
    
    try:
        result = brain.analyze_screen(temp_path, goal)
        
        print("\nğŸ [BRAIN RESPONSE]")
        if "error" in result:
            print(f"âŒ Error: {result['error']}")
        else:
            print(f"âœ… Target: {result.get('description', 'Unknown')}")
            print(f"ğŸ“ Coordinates: ({result.get('x')}, {result.get('y')})")
            print(f"ğŸ“Š JSON: {json.dumps(result)}")
            
            # 4. Optional: Simulation of Move (No Click for Safety)
            print("\nğŸ› ï¸ Action Simulation:")
            print(f"   - Moving mouse to ({result.get('x')}, {result.get('y')}) slowly...")
            # We move it slowly so the user can see.
            pyautogui.moveTo(result.get('x'), result.get('y'), duration=2.0)
            print("   - [Simulated Click] (Not actually clicking for safety)")
            
    except Exception as e:
        print(f"âŒ Unexpected Error: {e}")
    finally:
        # Cleanup
        if os.path.exists(temp_path):
            os.remove(temp_path)

if __name__ == "__main__":
    run_scenario()
